# DeepFake Detection Microservice

This microservice provides deepfake detection capabilities using an ONNX-quantized model (maybe ResNet), designed to work with the PurePost platform.

## Overview

The `dfdetect-service` is an independent microservice that analyzes images to detect potential deepfake manipulations. It communicates with the main Django application through a RESTful API and can be deployed as a separate container for improved scalability and resource isolation.

## Setup and Deployment

### Model Files

The service requires a pre-trained ONNX model for inference. Model files are mounted into the container using Docker volumes rather than being included in the container image.

[PTH files here](https://drive.google.com/file/d/13uGW2GpzFqSsaDlg3eJgLISLPVVsllY6/view?usp=sharing)
[ONNX files here](https://drive.google.com/drive/folders/1RDpiDjiX9IyoV4Zk5HfDfTOQPadhZnHP?usp=sharing)

**Required model files:**

- `model/ResNet18.onnx`: The quantized ResNet model
- `model/ResNet18_unoptimized.onnx`: The unoptimized model
- `model/labels.txt`: Class labels for model predictions

### Docker Volume Configuration

Model files are mounted as a volume in the `compose.yaml` file:

```yaml
volumes:
  - ./dfdetect_service/model:/app/model
```

This approach offers several advantages:

- Keeps container images small
- Allows model updates without rebuilding containers
- Supports different models in different environments
- Separates code from model artifacts

### Environment Setup

1. **Model Preparation**:

   - Place your quantized ONNX model in the `dfdetect_service/model/` directory
   - Ensure `labels.txt` is present in the same directory

2. **Directory Structure**:

   ```dir
   dfdetect_service/
   ├── app.py                 # FastAPI application
   ├── inference.py           # Model inference code
   ├── requirements.txt       # Python dependencies
   ├── Dockerfile             # Container configuration
   └── model/                 # Model directory (mounted as volume)
       ├── resnet_quantized.onnx  # The quantized model file
       └── labels.txt         # Class labels
   ```

## API Endpoints

The service exposes the following REST API endpoints:

- **POST /predict**

  - Accepts an image file for deepfake detection
  - Returns detection results with confidence scores
  - Results sorted by confidence score (highest first)
  - Example response:

    ```json
    {
      "success": true,
      "predictions": [
        {
          "label": "deepfake",
          "score": 0.9013320207595825
        },
        {
          "label": "real",
          "score": 0.09866794943809509
        }
      ],
      "processing_time": 0.009510517120361328
    }
    ```

- **GET /health**
  - Health check endpoint for monitoring
  - Returns service status information

## Deployment Options

### TODO: With Docker Compose

The service may be included in the project's `compose.yaml` with resource limits and health checks:

```yaml
dfdetect-service:
  build: ./dfdetect_service
  volumes:
    - ./dfdetect_service/model:/app/model
  deploy:
    resources:
      limits:
        cpus: "1.0"
        memory: 2G
  healthcheck:
    test: ["CMD", "curl", "-f", "http://localhost:5555/health"]
    interval: 30s
    timeout: 10s
    retries: 3
```

### Standalone Deployment

For standalone deployment with custom model location:

```bash
docker run -p 5555:5555 -v /path/to/models:/app/model dfdetect-service
```

## Performance Optimization

The service leverages ONNX Runtime optimizations for efficient inference:

- Quantized models reduce memory footprint by 70-80%
- Inference speed improved by 3-10x compared to non-quantized models
- Configured thread count optimizes CPU utilization
- LRU cache mechanism for repeated predictions

## Development and Testing

1. **Local testing without Docker**:

   ```bash
   cd dfdetect_service
   pip install -r requirements.txt
   python app.py
   ```

2. **Manual API testing**:

   ```bash
   curl -X POST http://localhost:5555/predict -F "file=@/path/to/test-image.jpg"
   ```

3. **Test with provide scripts**
   Note：The source of example deepfake test img in the repo: [DGM4](https://huggingface.co/datasets/rshaojimmy/DGM4) or mannually generated by stable diffusion.

   ```bash
   python tests/endpoints_test.py
   ```

4. **Build a image locally**

```bash
docker build -t dfdetect-service ./dfdetect_service

OR

docker build -t dfdetect-service .
```

## Troubleshooting

- **Model loading errors**: Verify model file path and format
- **Resource constraints**: Adjust memory and CPU limits in compose.yaml
- **Connection timeouts**: Check network configuration between services

---

For questions or assistance, please contact the development team.
